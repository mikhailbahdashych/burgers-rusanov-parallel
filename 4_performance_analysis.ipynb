{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Analysis for Parallel Burgers Solver\n",
    "\n",
    "This notebook analyzes the parallel performance of the MPI-based Burgers equation solver.\n",
    "\n",
    "## Performance Metrics\n",
    "\n",
    "### 1. Speedup\n",
    "$$S(P) = \\frac{T(1)}{T(P)}$$\n",
    "where $T(P)$ is execution time with $P$ processes.\n",
    "\n",
    "**Ideal:** $S(P) = P$ (linear speedup)\n",
    "\n",
    "### 2. Parallel Efficiency\n",
    "$$E(P) = \\frac{S(P)}{P} \\times 100\\%$$\n",
    "\n",
    "**Ideal:** $E(P) = 100\\%$\n",
    "\n",
    "### 3. Karp-Flatt Metric\n",
    "$$e = \\frac{\\frac{1}{S(P)} - \\frac{1}{P}}{1 - \\frac{1}{P}}$$\n",
    "\n",
    "Estimates the serial fraction of code. **Lower is better** (< 0.1 indicates good parallelization).\n",
    "\n",
    "## Data Sources\n",
    "\n",
    "Load timing data from:\n",
    "- `.npz` files generated by `2_parallel_rusanov.py` on PLGrid\n",
    "- JSON files with pre-computed timing results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Configure matplotlib\n",
    "plt.rcParams['figure.figsize'] = (14, 10)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs('plots', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Analyzer Class\n",
    "\n",
    "Core class for computing speedup, efficiency, and Karp-Flatt metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerformanceAnalyzer:\n",
    "    \"\"\"Analyze parallel performance metrics.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.timing_data = {}  # {n_procs: elapsed_time}\n",
    "        self.problem_size = None\n",
    "\n",
    "    def add_timing(self, n_procs, elapsed_time):\n",
    "        \"\"\"Add timing result for a given number of processes.\"\"\"\n",
    "        self.timing_data[n_procs] = elapsed_time\n",
    "\n",
    "    def load_from_npz_files(self, results_dir, grid_size):\n",
    "        \"\"\"\n",
    "        Load timing results from .npz result files.\n",
    "        \n",
    "        Args:\n",
    "            results_dir: Directory containing .npz files\n",
    "            grid_size: Grid size to analyze (e.g., 300, 600, 1200)\n",
    "        \"\"\"\n",
    "        results_path = Path(results_dir)\n",
    "        pattern = f\"burgers_nx{grid_size}_P*.npz\"\n",
    "\n",
    "        for result_file in results_path.glob(pattern):\n",
    "            # Extract process count from filename\n",
    "            match = re.search(r'P(\\d+)\\.npz', result_file.name)\n",
    "            if match:\n",
    "                n_procs = int(match.group(1))\n",
    "                data = np.load(result_file)\n",
    "\n",
    "                if 'elapsed_time' in data:\n",
    "                    self.add_timing(n_procs, float(data['elapsed_time']))\n",
    "                    if self.problem_size is None and 'nx' in data:\n",
    "                        self.problem_size = int(data['nx'])\n",
    "\n",
    "        if self.timing_data:\n",
    "            print(f\"Loaded timing data for {len(self.timing_data)} process counts\")\n",
    "        else:\n",
    "            print(f\"No timing data found for grid size {grid_size}\")\n",
    "\n",
    "    def compute_speedup(self):\n",
    "        \"\"\"Compute speedup: S(P) = T(1) / T(P)\"\"\"\n",
    "        if 1 not in self.timing_data:\n",
    "            raise ValueError(\"Sequential timing (P=1) required for speedup calculation\")\n",
    "\n",
    "        t_sequential = self.timing_data[1]\n",
    "        speedup = {}\n",
    "\n",
    "        for n_procs, t_parallel in self.timing_data.items():\n",
    "            speedup[n_procs] = t_sequential / t_parallel\n",
    "\n",
    "        return speedup\n",
    "\n",
    "    def compute_efficiency(self):\n",
    "        \"\"\"Compute parallel efficiency: E(P) = S(P) / P * 100%\"\"\"\n",
    "        speedup = self.compute_speedup()\n",
    "        efficiency = {}\n",
    "\n",
    "        for n_procs, s in speedup.items():\n",
    "            efficiency[n_procs] = (s / n_procs) * 100.0\n",
    "\n",
    "        return efficiency\n",
    "\n",
    "    def compute_karp_flatt(self):\n",
    "        \"\"\"Compute Karp-Flatt metric: e = (1/S(P) - 1/P) / (1 - 1/P)\"\"\"\n",
    "        speedup = self.compute_speedup()\n",
    "        karp_flatt = {}\n",
    "\n",
    "        for n_procs, s in speedup.items():\n",
    "            if n_procs == 1:\n",
    "                continue  # Not defined for P=1\n",
    "\n",
    "            numerator = (1.0 / s) - (1.0 / n_procs)\n",
    "            denominator = 1.0 - (1.0 / n_procs)\n",
    "            karp_flatt[n_procs] = numerator / denominator\n",
    "\n",
    "        return karp_flatt\n",
    "\n",
    "    def print_summary(self):\n",
    "        \"\"\"Print performance summary table.\"\"\"\n",
    "        speedup = self.compute_speedup()\n",
    "        efficiency = self.compute_efficiency()\n",
    "        karp_flatt = self.compute_karp_flatt()\n",
    "\n",
    "        n_procs_sorted = sorted(self.timing_data.keys())\n",
    "\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"PERFORMANCE ANALYSIS SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        if self.problem_size:\n",
    "            print(f\"Problem size: {self.problem_size} grid points\")\n",
    "\n",
    "        print(f\"\\n{'Procs':>6} {'Time (s)':>12} {'Speedup':>10} {'Efficiency':>12} {'Karp-Flatt':>12}\")\n",
    "        print(\"-\"*80)\n",
    "\n",
    "        for n_procs in n_procs_sorted:\n",
    "            t = self.timing_data[n_procs]\n",
    "            s = speedup[n_procs]\n",
    "            e = efficiency[n_procs]\n",
    "            kf = karp_flatt.get(n_procs, 0.0)\n",
    "\n",
    "            kf_str = f\"{kf:.6f}\" if n_procs > 1 else \"N/A\"\n",
    "            print(f\"{n_procs:6d} {t:12.6f} {s:10.4f} {e:11.2f}% {kf_str:>12}\")\n",
    "\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        # Analysis\n",
    "        print(\"\\nANALYSIS:\")\n",
    "        best_n_procs = max(speedup.keys(), key=lambda k: speedup[k])\n",
    "        best_speedup = speedup[best_n_procs]\n",
    "        print(f\"  => Best speedup: {best_speedup:.4f}x with {best_n_procs} processes\")\n",
    "\n",
    "        max_procs = max(n_procs_sorted)\n",
    "        max_efficiency = efficiency[max_procs]\n",
    "        print(f\"  => Efficiency at P={max_procs}: {max_efficiency:.2f}%\")\n",
    "\n",
    "        if len(karp_flatt) > 0:\n",
    "            avg_kf = np.mean(list(karp_flatt.values()))\n",
    "            print(f\"  => Average Karp-Flatt metric: {avg_kf:.6f}\")\n",
    "            print(f\"     (estimated serial fraction: {avg_kf*100:.4f}%)\")\n",
    "\n",
    "        if len(n_procs_sorted) >= 3:\n",
    "            last_three = n_procs_sorted[-3:]\n",
    "            speedups_last = [speedup[p] / p for p in last_three]\n",
    "            avg_scaled_speedup = np.mean(speedups_last)\n",
    "\n",
    "            if avg_scaled_speedup > 0.8:\n",
    "                scaling = \"Excellent\"\n",
    "            elif avg_scaled_speedup > 0.6:\n",
    "                scaling = \"Good\"\n",
    "            elif avg_scaled_speedup > 0.4:\n",
    "                scaling = \"Moderate\"\n",
    "            else:\n",
    "                scaling = \"Poor\"\n",
    "\n",
    "            print(f\"  => Scaling behavior: {scaling}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Results from PLGrid\n",
    "\n",
    "Specify the grid size you want to analyze. The analyzer will find all corresponding result files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "results_dir = 'results'  # Directory containing .npz files from PLGrid\n",
    "grid_size = 300          # Grid size to analyze (300, 600, 1200, etc.)\n",
    "\n",
    "# Create analyzer and load data\n",
    "analyzer = PerformanceAnalyzer()\n",
    "analyzer.load_from_npz_files(results_dir, grid_size)\n",
    "\n",
    "# Display loaded timings\n",
    "if analyzer.timing_data:\n",
    "    print(f\"\\nLoaded timings:\")\n",
    "    for n_procs in sorted(analyzer.timing_data.keys()):\n",
    "        print(f\"  P={n_procs:3d}: {analyzer.timing_data[n_procs]:.6f} seconds\")\n",
    "else:\n",
    "    print(f\"\\nNo data found! Check that results/{results_dir}/burgers_nx{grid_size}_P*.npz files exist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Summary Table\n",
    "\n",
    "Compute and display all performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary\n",
    "if analyzer.timing_data and 1 in analyzer.timing_data:\n",
    "    analyzer.print_summary()\n",
    "else:\n",
    "    print(\"Cannot compute performance metrics without sequential (P=1) timing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization: Scaling Analysis Plots\n",
    "\n",
    "Create comprehensive visualization showing:\n",
    "1. **Speedup** - actual vs ideal\n",
    "2. **Efficiency** - how well processors are utilized\n",
    "3. **Karp-Flatt** - serial fraction estimate\n",
    "4. **Execution Time** - wall-clock time vs process count\n",
    "5. **Log-Log Scaling** - identify scaling regimes\n",
    "6. **Summary Table** - numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if analyzer.timing_data and 1 in analyzer.timing_data:\n",
    "    speedup = analyzer.compute_speedup()\n",
    "    efficiency = analyzer.compute_efficiency()\n",
    "    karp_flatt = analyzer.compute_karp_flatt()\n",
    "\n",
    "    n_procs = sorted(speedup.keys())\n",
    "    speedup_vals = [speedup[p] for p in n_procs]\n",
    "    efficiency_vals = [efficiency[p] for p in n_procs]\n",
    "\n",
    "    # Ideal speedup for comparison\n",
    "    ideal_speedup = n_procs\n",
    "\n",
    "    # Create figure with subplots\n",
    "    fig = plt.figure(figsize=(16, 10))\n",
    "    gs = fig.add_gridspec(2, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "    # 1. Speedup (top left)\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax1.plot(n_procs, speedup_vals, 'bo-', linewidth=2, markersize=8,\n",
    "            label='Actual Speedup')\n",
    "    ax1.plot(n_procs, ideal_speedup, 'r--', linewidth=2, alpha=0.7,\n",
    "            label='Ideal Speedup')\n",
    "    ax1.set_xlabel('Number of Processes (P)', fontsize=12)\n",
    "    ax1.set_ylabel('Speedup S(P)', fontsize=12)\n",
    "    ax1.set_title('Strong Scaling: Speedup', fontsize=14, fontweight='bold')\n",
    "    ax1.legend(fontsize=10)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_xlim(left=0)\n",
    "    ax1.set_ylim(bottom=0)\n",
    "\n",
    "    # 2. Efficiency (top middle)\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax2.plot(n_procs, efficiency_vals, 'go-', linewidth=2, markersize=8)\n",
    "    ax2.axhline(y=100, color='r', linestyle='--', linewidth=2, alpha=0.7,\n",
    "               label='Ideal Efficiency')\n",
    "    ax2.axhline(y=80, color='orange', linestyle=':', linewidth=1.5, alpha=0.7,\n",
    "               label='80% Threshold')\n",
    "    ax2.set_xlabel('Number of Processes (P)', fontsize=12)\n",
    "    ax2.set_ylabel('Efficiency E(P) [%]', fontsize=12)\n",
    "    ax2.set_title('Parallel Efficiency', fontsize=14, fontweight='bold')\n",
    "    ax2.legend(fontsize=10)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_xlim(left=0)\n",
    "    ax2.set_ylim(bottom=0, top=110)\n",
    "\n",
    "    # 3. Karp-Flatt metric (top right)\n",
    "    if len(karp_flatt) > 0:\n",
    "        ax3 = fig.add_subplot(gs[0, 2])\n",
    "        kf_procs = sorted(karp_flatt.keys())\n",
    "        kf_vals = [karp_flatt[p] for p in kf_procs]\n",
    "        ax3.plot(kf_procs, kf_vals, 'mo-', linewidth=2, markersize=8)\n",
    "        ax3.set_xlabel('Number of Processes (P)', fontsize=12)\n",
    "        ax3.set_ylabel('Karp-Flatt Metric e', fontsize=12)\n",
    "        ax3.set_title('Karp-Flatt: Serial Fraction Estimate', fontsize=14, fontweight='bold')\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        ax3.set_xlim(left=0)\n",
    "\n",
    "        avg_kf = np.mean(kf_vals)\n",
    "        ax3.axhline(y=avg_kf, color='red', linestyle='--', alpha=0.5,\n",
    "                   label=f'Average: {avg_kf:.6f}')\n",
    "        ax3.legend(fontsize=10)\n",
    "\n",
    "    # 4. Execution time (bottom left)\n",
    "    ax4 = fig.add_subplot(gs[1, 0])\n",
    "    times = [analyzer.timing_data[p] for p in n_procs]\n",
    "    ax4.plot(n_procs, times, 'ro-', linewidth=2, markersize=8)\n",
    "    ax4.set_xlabel('Number of Processes (P)', fontsize=12)\n",
    "    ax4.set_ylabel('Execution Time [s]', fontsize=12)\n",
    "    ax4.set_title('Execution Time vs. Process Count', fontsize=14, fontweight='bold')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    ax4.set_xlim(left=0)\n",
    "    ax4.set_yscale('log')\n",
    "\n",
    "    # 5. Speedup on log-log scale (bottom middle)\n",
    "    ax5 = fig.add_subplot(gs[1, 1])\n",
    "    ax5.loglog(n_procs, speedup_vals, 'bo-', linewidth=2, markersize=8,\n",
    "              label='Actual Speedup')\n",
    "    ax5.loglog(n_procs, ideal_speedup, 'r--', linewidth=2, alpha=0.7,\n",
    "              label='Ideal (slope=1)')\n",
    "    ax5.set_xlabel('Number of Processes (P)', fontsize=12)\n",
    "    ax5.set_ylabel('Speedup S(P)', fontsize=12)\n",
    "    ax5.set_title('Log-Log Scaling Plot', fontsize=14, fontweight='bold')\n",
    "    ax5.legend(fontsize=10)\n",
    "    ax5.grid(True, alpha=0.3, which='both')\n",
    "\n",
    "    # 6. Performance table (bottom right)\n",
    "    ax6 = fig.add_subplot(gs[1, 2])\n",
    "    ax6.axis('off')\n",
    "\n",
    "    table_data = [['Procs', 'Time[s]', 'Speedup', 'Eff[%]']]\n",
    "    for p in n_procs:\n",
    "        row = [\n",
    "            f\"{p}\",\n",
    "            f\"{analyzer.timing_data[p]:.4f}\",\n",
    "            f\"{speedup[p]:.2f}\",\n",
    "            f\"{efficiency[p]:.1f}\"\n",
    "        ]\n",
    "        table_data.append(row)\n",
    "\n",
    "    table = ax6.table(cellText=table_data, cellLoc='center', loc='center',\n",
    "                     bbox=[0, 0, 1, 1])\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.scale(1, 2)\n",
    "\n",
    "    # Style header row\n",
    "    for i in range(4):\n",
    "        table[(0, i)].set_facecolor('#4CAF50')\n",
    "        table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "\n",
    "    # Alternate row colors\n",
    "    for i in range(1, len(table_data)):\n",
    "        color = '#f0f0f0' if i % 2 == 0 else 'white'\n",
    "        for j in range(4):\n",
    "            table[(i, j)].set_facecolor(color)\n",
    "\n",
    "    ax6.set_title('Performance Summary', fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "    # Overall title\n",
    "    title = 'Strong Scaling Analysis: Burgers Equation (Rusanov Method)'\n",
    "    if analyzer.problem_size:\n",
    "        title += f'\\nProblem Size: {analyzer.problem_size} grid points'\n",
    "    plt.suptitle(title, fontsize=18, fontweight='bold', y=0.995)\n",
    "\n",
    "    output_file = f'plots/scaling_analysis_nx{grid_size}.png'\n",
    "    plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\nSaved: {output_file}\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Cannot create plots without timing data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Analyze Multiple Grid Sizes\n",
    "\n",
    "If you ran experiments with different grid sizes, compare their scaling behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze multiple grid sizes\n",
    "grid_sizes = [300, 600, 1200]  # Adjust based on your experiments\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "for nx in grid_sizes:\n",
    "    analyzer_multi = PerformanceAnalyzer()\n",
    "    analyzer_multi.load_from_npz_files(results_dir, nx)\n",
    "    \n",
    "    if analyzer_multi.timing_data and 1 in analyzer_multi.timing_data:\n",
    "        speedup = analyzer_multi.compute_speedup()\n",
    "        efficiency = analyzer_multi.compute_efficiency()\n",
    "        \n",
    "        n_procs = sorted(speedup.keys())\n",
    "        speedup_vals = [speedup[p] for p in n_procs]\n",
    "        efficiency_vals = [efficiency[p] for p in n_procs]\n",
    "        \n",
    "        # Speedup comparison\n",
    "        ax1.plot(n_procs, speedup_vals, 'o-', linewidth=2, markersize=6,\n",
    "                label=f'nx={nx}', alpha=0.7)\n",
    "        \n",
    "        # Efficiency comparison\n",
    "        ax2.plot(n_procs, efficiency_vals, 'o-', linewidth=2, markersize=6,\n",
    "                label=f'nx={nx}', alpha=0.7)\n",
    "\n",
    "# Ideal lines\n",
    "if n_procs:\n",
    "    ax1.plot(n_procs, n_procs, 'k--', linewidth=2, alpha=0.5, label='Ideal')\n",
    "    ax2.axhline(y=100, color='k', linestyle='--', linewidth=2, alpha=0.5, label='Ideal')\n",
    "\n",
    "ax1.set_xlabel('Number of Processes', fontsize=12)\n",
    "ax1.set_ylabel('Speedup', fontsize=12)\n",
    "ax1.set_title('Speedup Comparison', fontsize=14, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.set_xlabel('Number of Processes', fontsize=12)\n",
    "ax2.set_ylabel('Efficiency [%]', fontsize=12)\n",
    "ax2.set_title('Efficiency Comparison', fontsize=14, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Multi-Grid Scaling Comparison', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "\n",
    "output_file = 'plots/scaling_comparison_all_grids.png'\n",
    "plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "print(f\"Saved: {output_file}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook provides comprehensive performance analysis for the parallel Burgers solver:\n",
    "\n",
    "### Key Findings\n",
    "- **Speedup**: How much faster the parallel version runs\n",
    "- **Efficiency**: How well the code utilizes available processors\n",
    "- **Scalability**: Whether performance continues to improve with more processes\n",
    "- **Serial Fraction**: Estimated portion of code that cannot be parallelized\n",
    "\n",
    "### Expected Behavior\n",
    "- Good scaling (80%+ efficiency) for 2-8 processes on moderate grids\n",
    "- Better scaling for larger problems (higher nx)\n",
    "- Communication overhead becomes significant beyond ~16-32 processes\n",
    "\n",
    "### Next Steps\n",
    "- Experiment with larger grid sizes for better parallel efficiency\n",
    "- Compare different MPI implementations\n",
    "- Analyze strong vs weak scaling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
